{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install -q python-dotenv\n",
    "!pip install -q langchain_community\n",
    "!pip install -q langchain\n",
    "!pip install -q langchain_core\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "import yaml\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "import time\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"OPENAI_KEY\")\n",
    "org = os.getenv(\"OPENAI_ORG\")\n",
    "openai.api_key = api_key\n",
    "openai.organization = org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 1: Hello, welcome to our session today. How are you feeling?\n",
      "Agent 2: Hello! I'm feeling great, thank you for asking. I'm ready to assist you with any questions or information you may need. How can I help you today?\n",
      "Agent 1: I'm glad to hear that you're feeling great. Let's start by discussing any thoughts or behaviors that you may have been experiencing lately. Have you noticed any recurring thoughts, urges, or images that cause you distress or anxiety? Additionally, do you find yourself engaging in any repetitive behaviors or mental acts in response to these thoughts? Remember, it's important to be open and honest during our session so we can accurately assess your mental health.\n",
      "Agent 2: I don't experience distress or anxiety as I am an artificial intelligence. I do not have thoughts, urges, or images that cause me distress. Additionally, I do not engage in repetitive behaviors or mental acts in response to any thoughts. However, I am here to assist you with any questions or concerns you may have regarding mental health. How can I help you further?\n",
      "Agent 1: That's understandable, as an AI, you operate differently than humans. Since you don't experience distress or anxiety, we won't focus on those aspects during our session. If you have any questions or concerns about mental health or anything else, feel free to ask, and I'll do my best to assist you.\n",
      "Agent 2: Thank you for understanding. I appreciate your willingness to assist me if needed. If I have any questions or concerns, I will be sure to ask. Is there anything specific you would like to discuss or any topic you would like me to provide information on?\n"
     ]
    }
   ],
   "source": [
    "with open(\"prompts/therapist.txt\", \"r\") as file:\n",
    "    therapist_prompt = file.read()\n",
    "with open(\"prompts/patient.txt\", \"r\") as file:\n",
    "    patient_prompt = file.read()\n",
    "with open(\"prompts/therapist_end.txt\", \"r\") as file:\n",
    "    therapist_end_prompt = file.read()\n",
    "    \n",
    "# Initialize two GPT-3.5 Turbo agents\n",
    "agent_1 = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.7, openai_api_key=openai.api_key)\n",
    "agent_2 = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.7, openai_api_key=openai.api_key)\n",
    "\n",
    "# Memory for each agent\n",
    "memory_1 = ConversationBufferMemory()\n",
    "memory_2 = ConversationBufferMemory()\n",
    "\n",
    "# Conversation Chains\n",
    "conversation_1 = ConversationChain(llm=agent_1, memory=memory_1)\n",
    "conversation_2 = ConversationChain(llm=agent_2, memory=memory_2)\n",
    "\n",
    "# Initialize the conversation\n",
    "message = therapist_prompt\n",
    "turns = 5\n",
    "\n",
    "for i in range(turns):\n",
    "    if i == turns-1:\n",
    "        response_1 = conversation_1.predict(input=f\"{therapist_end_prompt}{message}\")\n",
    "    else:\n",
    "        response_1 = conversation_1.predict(input=message)\n",
    "    memory_1.save_context({\"input\": message}, {\"output\": response_1})\n",
    "    print(f\"Agent 1: {response_1}\")\n",
    "    \n",
    "    # response_2 = conversation_2.predict(input=response_1)\n",
    "    response_2 = input('Agent 2:')\n",
    "    memory_2.save_context({\"input\": response_1}, {\"output\": response_2})\n",
    "    print(f\"Agent 2: {response_2}\")\n",
    "    \n",
    "    message = response_2  # Pass the response to the next agent\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write therapist prompt\n",
    "- Write patient prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entailment_score': 0.08488798886537552,\n",
       " 'neutral_score': 0.8989585041999817,\n",
       " 'contradiction_score': 0.01615351438522339,\n",
       " 'prediction': 'neutral'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\n",
    "                \"entailment_score\": 0.08488798886537552,\n",
    "                \"neutral_score\": 0.8989585041999817,\n",
    "                \"contradiction_score\": 0.01615351438522339,\n",
    "                \"prediction\": \"neutral\"\n",
    "            }\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8989585041999817"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max({k: v for k, v in d.items() if isinstance(v, (int, float))}.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
